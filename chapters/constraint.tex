\section{Basic building blocks of \zkwasm\ circuits}
\label{chp:build-blocks}
As described in Section \ref{chp:encode-state-in-circuits}, the arithmetic circuit of execution trace is crucial in constructing SNARKS of WASM virtual machine. In this section we will give a brief of some basic techniques and elementary circuits used to construct our final arithmetic circuits in \zkwasm.


%From a circuit description we can generate a proving key and a verification key, which are needed for the operations of proving and verification for that circuit.

\subsection{Representing Basic Types in Halo2 Constraint System}

Recall that to prove an arithmetic circuit matrix with constraint $\mathbf{C}$ holds, the Plonkish proof system interpolates each column $c_i$ into polynomials $c_i(x)$ such that $c_i(j) = c_{ij}$ and then uses KCG commitment scheme to prove $\mathcal{C}(c_i(x)) = 0$ holds for all $x=1,2,3,\cdots$. 

However, to use KZG commitment scheme on polynomial $c_i$, we require $c_i(x) \in \mathbf{F}$ where $\mathbf{F}$ is the scalar field of some elliptic curve $\mathbf{C}$. Therefore, each $c_i(j)$ is in the scalar field $\mathbf{F}$ of the elliptic curve $\mathbf{C}$ in Halo2's arithmetic circuit system. Since the basic types in WASM are i64 and i32 which do not match the number field $\mathbf{F}$ in Halo2, we need to add a constraint $x<2^{32}$ (or $x< 2^{64}$) to represent a variable $x$ with type $i32$ or $i64$. In \zkwasm, we use $\mathbf{T_N}$ to denote a table containing elements from $0$ to $2^N-1$ and then we use a polynomial lookup to prove that values of some column $c_i$ are less than $2^N-1$ by $plookup(\mathbf{T_N}, c_i(j)) = 0$. When $N$ is large (e.g. 64) and $\mathbf{T_N}$ becomes too big, we will decompose an i64 into several parts and prove that each part is less then $2^8-1$. Below we use the notation $x \in \mathbf{T_N}$ to denote $x < 2^N$ and omit the details of decomposing $x$ into small pieces when necessary.

\subsection{Representing Map Using Polynomial Lookup of Tables}
\label{chp:map-repr}

Other than specifying a range for cells, another usage of polynomial lookup is that we can encode the state of key-value map into tables and use polynomial lookup to specify the semantics of getting a value of a certain key in a map. 

Here is an example. Recall that we represent the state of \zkwasm\, by \fullstate \, where $\mathcal{C}$ and $\mathcal{H}$ are fixed by the WASM image. We encode state $\mathcal{C}$ and $\mathcal{H}$ in tables $\mathbf{T}_\mathcal{C} : Address \times Opcode$ and $\mathbf{T}_\mathcal{H}: Address \times U64$. By doing this, we can use the polynomial lookup to specify the semantic of getting opcode $op$ at address $addr$ in $\mathcal{C}$ by $(iaddr, op) \in \mathbf{T}_\mathcal{C}$ and specify the semantic of WASM of getting the initial byte data $v$ at address $addr$ in $\mathcal{H}$ by $(d, addr) \in \mathbf{T}_\mathcal{H}$.

\subsection{Representing Math Semantic as Arithmetic Circuits}
According to the WASM specification, the semantics of opcodes are usually defined as mathematical equations and state transformation. Thus we need to construct arithmetic circuits to enforce the semantics of the opcodes. For example, suppose that the opcode $div_u$ (a division of unsigned int) has the following semantics:
\[ div_u(a, b) = (a - a \bmod b) \div b \] 
It follows that to write the above mathematical definition into polynomial constraints we need to introduce intermediate witness $r$ such that the above semantics can be rewritten as follows:
\begin{equation}
\begin{cases}
    a = div_u(a,b) * b + r \\
    r < b
\end{cases}
\end{equation}
However, since $r$ and $b$ are in $\mathbf{F}$, it needs more work to represent $r < b$ into polynomial constraints. Fortunately, in \zkwasm, we use range check to constraint $r$ and $b$ within 64 bits. The above constraints can be further rewritten into the following polynomial constraints with one more extra witness $k$: 
\begin{equation}
\begin{cases}
    a = div_u(a,b) * b + r \\
    b = r + k \\
    a, r, b, k\in T_{64}, 
\end{cases}
\end{equation}
When dealing with opcode that has more complicated mathematical semantics, we need a way to formally prove that the derived constraints represent the same semantic. In \zkwasm, we use Z3 to formally check that the mathematical definition is correctly refined to the arithmetic circuits.

\subsection{Enforcing Valid Dynamic State Accessing using Polynomial Lookup Tables}
Given a sequence of state transition function $\{t_i\}$ such that each transition might read or write finitely many key-value pairs (e.g. access memory $\mathcal{M}$, stack $\mathcal{SP}$ or global $\mathcal{G}$) in the state $\mathcal{S}$. We label each read or write of $\{t_i\}$ in a sub sequence $\{t_i^k\}$ and use the tuple $(tid=i, mid=k, accessType, address, value)$ to denote the access log of $\{t_i^k\}$ such that each access log has the following semantic:
\begin{itemize}
    \item Init memory: $(tid, mid, init, addr, v ) := \{ s.addr = v; \}$
    \item Write value $v$ to memory: $(tid, mid, write, addr, v) := \{ s.addr = v; \}$
    \item Read from memory: $(tid, mid, read, addr, v) := \{assert(s.addr \equiv v);\}$
\end{itemize}

As the address in $t_i^k$ can be randomly distributed which makes it hard to reason about the fact that a read from a address $addr$ should get the value $v$ that related to the latest write or init of that $addr$. To solve this, we do the following. First, we create a lookup table $\mathbf{T}$ by rearranging the log by their access address and order them by (tid, mid) within each address block (see Table \ref{tbl:rw-table}).
\begin{table}[!h]
\begin{center}
\caption{Memory access table}
\label{tbl:rw-table}
\begin{tabular}{ | c | c | c | c | }
  \hline
  address & id = (tid, mid) & accessType & value \\ 
  \hline
 $addr_1$ & $tid_1$ &  $acc_1$ & $v_1$ \\  
 $addr_1$ & $tid_2$ &  $acc_2$ & $v_2$ \\
  $addr_1$ & $tid_3$ &  $acc_3$ & $v_3$ \\  
 \hline
 $addr_2$ & $tid_4$ &  $acc_3$ & $v_4$ \\  
 $addr_2$ & $tid_5$ & $acc_4$ & $v_5$ \\
 \hline
 $\cdots$ & $tid_k$ & $acc_k$ & $v_k$ \\
 \hline
\end{tabular}

\end{center}
\end{table}

\noindent Second, we enforce the semantic of init, read and write by equip Table \ref{tbl:rw-table} with constraints of each row using Equation \ref{eq:rw-constraints}.
\begin{equation}
\label{eq:rw-constraints}
\mathbf{C}_{\mathbf{T}}(cur) = \begin{cases}
    &r(cur).address \equiv r(next).address \rightarrow r(cur).id \le r(next).id \\
    %&r(cur).accessType \equiv init \rightarrow r.(previous).address \neq r.(cur).address \\
    &r(next).accessType \equiv read \rightarrow r(next).value \equiv r(cur).value \\
    &r(cur).address \neq r(prev).address \leftrightarrow r(cur).accessType \equiv init \\
    &r(cur).address \neq r(prev).address \rightarrow r(cur).address > r.(next).address
\end{cases}
\end{equation}
\begin{remark}
Rearranging means the map from access log to $\mathbf{T}$ is a one to one map.
The first constraint enforces that for access logs visiting the same address, they are sorted by their accessing order.  The second constraint enforces that the read access get the correct value and the third constraint enforces that init happens once and only once at the beginning of each address block. 
\end{remark}
\begin{theorem}
\label{thm:one-one-rw-1}
Give an memory access log ${L_i}$, the log ${L_i}$ is valid if there exists a table $\mathbf{T}$ such that $\mathbf{T}$ satisfies the above constraints and each $L_i$ is in $\mathbf{T}$ and vice versa. 
\end{theorem}
\begin{proof}
First, for init access log, the only constraint we need to enforce is that each address can only be init once. Suppose there are two init access logs $L_a$ and $L_b$ init the same address in the access log ${L_i}$, then they must both exists in $\mathbf{T}$ in the same address block, which contradicts the third constraint of Equation \ref{eq:rw-constraints}. Second, for read access log $L_r = (tid, mid, read, addr, v)$, we need to prove that the latest write or init access log $L_{latest}$ to $addr$ has put value $v$ into $addr$. Consider the second constraint of Equation \ref{eq:rw-constraints}, it is sufficient to prove that the $L_{latest}$ is the closest entry to $L_r$ in $\mathbf{T}$. Suppose that $L_{latest}$ is not the closest rewrite (init) entry to $L_r$ in $\mathbf{T}$, then there exists another write access log $L_o$ between $L_{latest}$ and $L_r$ such that $L_o.id > L_{latest}.id$ (by the first constraint of Equation \ref{eq:rw-constraints}) which means that $L_o$ is the latest update of $addr$ and contradicts the assumption. In the end, all the write access are valid because all the parameters are explicit.
\end{proof}
In the end, as a consequence of Theorem \ref{thm:one-one-rw-1}, given any read access at address $addr$ with fixed $tid$, $mid$ and $accessType$, we can check the validity of the return value $v$ by checking $(t_i, mid, accessType, addr, v) \in T$.

